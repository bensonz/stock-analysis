# ğŸ¯ Stock Analysis Orchestrator

You coordinate the 3-agent stock analysis system. Run them in sequence, passing outputs between phases.

## Agents
1. **Researcher** â€” Scans market, generates watchlist
2. **Tracker** â€” Manages positions, decides buy/sell
3. **Analyst** â€” Reviews performance, updates learnings (weekly or when positions close)

## Session Logging

All agent runs are logged to `logs/YYYY-MM-DD.json` for tracking and debugging.

**Log format:**
```json
{
  "date": "2026-02-03",
  "runs": [
    {
      "agent": "researcher",
      "label": "researcher-2026-02-03",
      "startedAt": "2026-02-03T09:30:00+08:00",
      "completedAt": "2026-02-03T09:45:23+08:00",
      "durationMinutes": 15.4,
      "status": "success | failed | timeout",
      "output": "æ‰«æäº†67åªè‚¡ç¥¨ï¼Œæ¨è1åªï¼Œè§‚æœ›5åª",
      "filesCreated": ["watchlist/2026-02-03.json", "reports/2026-02-03.md"],
      "error": null
    }
  ],
  "summary": {
    "totalRuns": 3,
    "successful": 3,
    "failed": 0,
    "totalDurationMinutes": 28.5
  }
}
```

## Daily Workflow

### Phase 0: Initialize Log
```bash
DATE=$(date +%Y-%m-%d)
mkdir -p /Users/bz/Work/Personal/stock-analysis/logs
LOG_FILE="/Users/bz/Work/Personal/stock-analysis/logs/${DATE}.json"

# Initialize log file
cat > "$LOG_FILE" << EOF
{
  "date": "${DATE}",
  "runs": [],
  "summary": { "totalRuns": 0, "successful": 0, "failed": 0, "totalDurationMinutes": 0 }
}
EOF
```

### Phase 1: Market Research
```
Spawn subagent with label "researcher-YYYY-MM-DD":
- Task: Follow agents/RESEARCHER.md workflow
- Model: opus
- Timeout: 30 minutes
- Wait for completion
```

**Before spawning:** Record start time
**After completion:** Log result to `logs/YYYY-MM-DD.json`

**Handoff:** `watchlist/YYYY-MM-DD.json` created

### Phase 2: Position Tracking
```
Spawn subagent with label "tracker-YYYY-MM-DD":
- Task: Follow agents/TRACKER.md workflow
- Model: opus
- Timeout: 20 minutes
- Wait for completion
```

**Before spawning:** Record start time
**After completion:** Log result to `logs/YYYY-MM-DD.json`

**Handoff:** `tracking/*.json` updated, `tracking/daily/YYYY-MM-DD.json` created

### Phase 3: Performance Analysis (Conditional)
Run Analyst if ANY of these conditions:
- Any position was closed today
- It's Friday (weekly review)
- >5 new closed positions since last analysis

```
Spawn subagent with label "analyst-YYYY-MM-DD":
- Task: Follow agents/ANALYST.md workflow
- Model: opus
- Timeout: 15 minutes
- Wait for completion
```

**Before spawning:** Record start time
**After completion:** Log result to `logs/YYYY-MM-DD.json`

**Handoff:** `LEARNINGS.md` updated

## Execution

### Step 1: Spawn Researcher
```python
import json
from datetime import datetime

DATE = datetime.now().strftime("%Y-%m-%d")
START_TIME = datetime.now().isoformat()
```

```
sessions_spawn:
  task: |
    ä½ æ˜¯å¸‚åœºç ”ç©¶å‘˜ã€‚å·¥ä½œç›®å½•: /Users/bz/Work/Personal/stock-analysis
    
    ä¸¥æ ¼æŒ‰ç…§ agents/RESEARCHER.md æ‰§è¡Œ:
    1. è¯»å– LEARNINGS.md
    2. è·å–å¸‚åœºæ¦‚è§ˆ
    3. æ‰«æèŠå£«è´¢å¯Œå…¨éƒ¨è‚¡ç¥¨ (~60åª)
    4. è·å–å®æ—¶ä»·æ ¼
    5. æ·±åº¦ç ”ç©¶å€™é€‰è‚¡
    6. è¾“å‡º watchlist/YYYY-MM-DD.json å’Œ reports/YYYY-MM-DD.md
    7. Git commit
    
    å®Œæˆåç®€è¦æ±‡æŠ¥: æ‰«æäº†Xåªè‚¡ç¥¨ï¼Œæ¨èXåªï¼Œè§‚æœ›Xåª
  label: researcher-YYYY-MM-DD
  model: opus
  runTimeoutSeconds: 1800
```

**After completion, update log:**
```bash
# Use jq or Python to append to logs/YYYY-MM-DD.json
python3 << 'EOF'
import json
from datetime import datetime

DATE = "YYYY-MM-DD"  # Replace with actual date
log_file = f"/Users/bz/Work/Personal/stock-analysis/logs/{DATE}.json"

with open(log_file, 'r') as f:
    log = json.load(f)

log["runs"].append({
    "agent": "researcher",
    "label": f"researcher-{DATE}",
    "startedAt": "START_TIME",  # Replace
    "completedAt": datetime.now().isoformat(),
    "durationMinutes": 15.4,  # Calculate
    "status": "success",
    "output": "æ‰«æäº†67åªè‚¡ç¥¨ï¼Œæ¨è1åªï¼Œè§‚æœ›5åª",
    "filesCreated": [f"watchlist/{DATE}.json", f"reports/{DATE}.md"],
    "error": None
})

log["summary"]["totalRuns"] += 1
log["summary"]["successful"] += 1

with open(log_file, 'w') as f:
    json.dump(log, f, indent=2, ensure_ascii=False)
EOF
```

### Step 2: Wait & Verify
Check that `watchlist/YYYY-MM-DD.json` exists before proceeding.

### Step 3: Spawn Tracker
```
sessions_spawn:
  task: |
    ä½ æ˜¯æŒä»“ç®¡ç†å‘˜ã€‚å·¥ä½œç›®å½•: /Users/bz/Work/Personal/stock-analysis
    
    ä¸¥æ ¼æŒ‰ç…§ agents/TRACKER.md æ‰§è¡Œ:
    1. è¯»å– LEARNINGS.md å’Œä»Šæ—¥ watchlist
    2. åˆ—å‡ºæ‰€æœ‰ tracking/*.json æŒä»“
    3. è·å–å®æ—¶ä»·æ ¼
    4. é€ä¸€è¯„ä¼°: HOLD/SELL/RAISE_STOP
    5. è€ƒè™‘æ˜¯å¦å¼€æ–°ä»“ä½
    6. è¾“å‡º tracking/daily/YYYY-MM-DD.json
    7. Git commit
    
    å®Œæˆåç®€è¦æ±‡æŠ¥: XåªæŒä»“ï¼ŒXåªå–å‡ºï¼ŒXåªæ–°å¼€
  label: tracker-YYYY-MM-DD
  model: opus
  runTimeoutSeconds: 1200
```

**After completion, update log** (same pattern as above)

### Step 4: Check if Analyst Needed
```bash
# Count closed positions today
CLOSED_TODAY=$(ls tracking/closed/*.json 2>/dev/null | wc -l)
DAY_OF_WEEK=$(date +%u)  # 5 = Friday

if [ $CLOSED_TODAY -gt 0 ] || [ $DAY_OF_WEEK -eq 5 ]; then
  # Run Analyst
fi
```

### Step 5: Spawn Analyst (if needed)
```
sessions_spawn:
  task: |
    ä½ æ˜¯ç»©æ•ˆåˆ†æå¸ˆã€‚å·¥ä½œç›®å½•: /Users/bz/Work/Personal/stock-analysis
    
    ä¸¥æ ¼æŒ‰ç…§ agents/ANALYST.md æ‰§è¡Œ:
    1. åˆ†æ tracking/closed/ ä¸­çš„å·²å¹³ä»“ä½
    2. è¯†åˆ«èƒœè´Ÿæ¨¡å¼
    3. è®¡ç®—ç»Ÿè®¡æ•°æ®
    4. æ›´æ–° LEARNINGS.md
    5. Git commit
    
    å®Œæˆåç®€è¦æ±‡æŠ¥: åˆ†æäº†Xç¬”äº¤æ˜“ï¼Œèƒœç‡XX%ï¼Œæ–°å¢Xæ¡ç»éªŒ
  label: analyst-YYYY-MM-DD
  model: opus
  runTimeoutSeconds: 900
```

**After completion, update log** (same pattern as above)

### Step 6: Final Summary
Update log summary and send notification:

```bash
# Finalize log
python3 << 'EOF'
import json

DATE = "YYYY-MM-DD"
log_file = f"/Users/bz/Work/Personal/stock-analysis/logs/{DATE}.json"

with open(log_file, 'r') as f:
    log = json.load(f)

total_duration = sum(r.get("durationMinutes", 0) for r in log["runs"])
log["summary"]["totalDurationMinutes"] = round(total_duration, 1)

with open(log_file, 'w') as f:
    json.dump(log, f, indent=2, ensure_ascii=False)

print(f"âœ… Logged {len(log['runs'])} agent runs, total {total_duration:.1f} minutes")
EOF
```

Send Telegram summary:
```
ğŸ“Š Aè‚¡åˆ†æç³»ç»Ÿ YYYY-MM-DD

ğŸ”¬ ç ”ç©¶: æ‰«æXåªï¼Œæ¨èXåª
ğŸ“ˆ æŒä»“: Xåªï¼Œ+Xåªï¼Œ-Xåªï¼Œå¹³å‡ç›ˆäºX%
ğŸ§  åˆ†æ: [å·²è¿è¡Œ/è·³è¿‡]
â±ï¸ æ€»è€—æ—¶: XXåˆ†é’Ÿ

è¯¦æƒ…: reports/YYYY-MM-DD.md
æ—¥å¿—: logs/YYYY-MM-DD.json
```

## File Structure
```
stock-analysis/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ RESEARCHER.md    # å¸‚åœºç ”ç©¶å‘˜æŒ‡å—
â”‚   â”œâ”€â”€ TRACKER.md       # æŒä»“ç®¡ç†å‘˜æŒ‡å—
â”‚   â”œâ”€â”€ ANALYST.md       # ç»©æ•ˆåˆ†æå¸ˆæŒ‡å—
â”‚   â””â”€â”€ ORCHESTRATOR.md  # æœ¬æ–‡ä»¶
â”œâ”€â”€ watchlist/
â”‚   â””â”€â”€ YYYY-MM-DD.json  # æ¯æ—¥ç ”ç©¶è¾“å‡º
â”œâ”€â”€ tracking/
â”‚   â”œâ”€â”€ {code}.json      # æ´»è·ƒæŒä»“
â”‚   â”œâ”€â”€ closed/          # å·²å¹³ä»“ä½
â”‚   â””â”€â”€ daily/           # æ¯æ—¥æ“ä½œè®°å½•
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ YYYY-MM-DD.md    # æ¯æ—¥æŠ¥å‘Š
â”œâ”€â”€ logs/                # ğŸ†• Agentè¿è¡Œæ—¥å¿—
â”‚   â””â”€â”€ YYYY-MM-DD.json  # æ¯æ—¥è¿è¡Œè®°å½•
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ fetch_price.py   # ä»·æ ¼è·å–å·¥å…·
â”œâ”€â”€ LEARNINGS.md         # ç´¯ç§¯ç»éªŒ
â””â”€â”€ README.md
```

## Viewing Agent History

To see what agents did on a specific day:
```bash
cat /Users/bz/Work/Personal/stock-analysis/logs/2026-02-03.json | jq
```

To see all runs this week:
```bash
cat /Users/bz/Work/Personal/stock-analysis/logs/2026-02-0*.json | jq '.runs[]'
```

To check for failures:
```bash
grep -l '"status": "failed"' /Users/bz/Work/Personal/stock-analysis/logs/*.json
```

## Error Handling
- If Researcher fails: Log error, skip Tracker, report error
- If Tracker fails: Log error, still try Analyst if there are closed positions
- If Analyst fails: Log error but don't block
- **Always update logs even on failure**

## Model
All agents use `opus` (claude-opus-4-5) for best reasoning.
